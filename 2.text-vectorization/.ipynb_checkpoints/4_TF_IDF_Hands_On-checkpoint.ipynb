{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "DAfvNMjVzO9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "      'this is the first document',\n",
        "      'this document is the second document',\n",
        "      'and this is the third one',\n",
        "      'is this the first document',\n",
        " ] \n",
        "def IDF(corpus, unique_words):\n",
        "  idf_dict={}\n",
        "  N=len(corpus)\n",
        "  for i in unique_words:\n",
        "    count=0\n",
        "    for sen in corpus:\n",
        "      if i in sen.split():\n",
        "        count=count+1\n",
        "      idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
        "  return idf_dict "
      ],
      "metadata": {
        "id": "GNTKp2AUyDwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(whole_data):\n",
        "  unique_words = set()\n",
        "  if isinstance(whole_data, (list,)):\n",
        "    for x in whole_data:\n",
        "      for y in x.split():\n",
        "        if len(y)<2:\n",
        "          continue\n",
        "        unique_words.add(y)\n",
        "    unique_words = sorted(list(unique_words))\n",
        "    vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "    Idf_values_of_all_unique_words=IDF(whole_data,unique_words)\n",
        "  return vocab, Idf_values_of_all_unique_words\n",
        "Vocabulary, idf_of_vocabulary=fit(corpus)"
      ],
      "metadata": {
        "id": "QVz4lQouy0ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(Vocabulary.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywxhFp1Cy44l",
        "outputId": "833f15aa-4171-4518-c9b7-177c2d4f7824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(idf_of_vocabulary.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt7AHd4uzB19",
        "outputId": "d2fa24a9-438d-4541-9be8-68a3ca02c059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(dataset,vocabulary,idf_values):\n",
        "     sparse_matrix= csr_matrix( (len(dataset), len(vocabulary)), dtype=np.float64)\n",
        "     for row  in range(0,len(dataset)):\n",
        "       number_of_words_in_sentence=Counter(dataset[row].split())\n",
        "       for word in dataset[row].split():\n",
        "           if word in  list(vocabulary.keys()):\n",
        "               tf_idf_value=(number_of_words_in_sentence[word]/len(dataset[row].split()))*(idf_values[word])\n",
        "               sparse_matrix[row,vocabulary[word]]=tf_idf_value\n",
        "     print(\"NORM FORM\\n\",normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False))\n",
        "     output =normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
        "     return output\n",
        "final_output=transform(corpus,Vocabulary,idf_of_vocabulary)\n",
        "print(final_output.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohT2JyVYzD9w",
        "outputId": "1069799c-a48b-42f5-e384-95ed3abf540d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NORM FORM\n",
            "   (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "  (1, 1)\t0.6876235979836937\n",
            "  (1, 3)\t0.2810886740337529\n",
            "  (1, 5)\t0.5386476208856762\n",
            "  (1, 6)\t0.2810886740337529\n",
            "  (1, 8)\t0.2810886740337529\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.4697913855799205\n",
            "  (3, 2)\t0.580285823684436\n",
            "  (3, 3)\t0.3840852409148149\n",
            "  (3, 6)\t0.3840852409148149\n",
            "  (3, 8)\t0.3840852409148149\n",
            "(4, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_output[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmKemA1ZzJAb",
        "outputId": "6b1ef538-7052-48dc-d99c-c885ea8ae918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRi8wyXozfoM",
        "outputId": "62096abd-0fa8-4218-c05b-9349fafadddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524],\n",
              "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
              "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
              "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
              "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
              "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VbMX9FZAzkb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}